{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e0efa-fc79-4d45-9735-b514c2a2c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install oracledb openai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36eb4c59-869f-4831-897c-56512cf80163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Google Gemini API key:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Documents\\Tickets\\v4_PLSQL_AI_Tool\\ModifiedV4\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CONFIGURATION CELL - SET ALL VARIABLES HERE\n",
    "# ====================================================================\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# USER CONFIGURATION\n",
    "# =========================\n",
    "\n",
    "# API Configuration\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google Gemini API key: \")\n",
    "\n",
    "# Package Configuration - ADD YOUR PACKAGES HERE\n",
    "PACKAGES_TO_PROCESS = [\n",
    "    \"GIN_STP_PKG\",\n",
    "    \"GIN_ACCOUNTS_PKG\",\n",
    "]\n",
    "\n",
    "# Database Configurations - MODIFY THESE FOR YOUR DATABASES\n",
    "DATABASE_CONFIGS = {\n",
    "    \"DATABASE_A\": { \n",
    "        \"host\": \"10.176.18.91\",\n",
    "        \"port\": 1522,\n",
    "        \"service_name\": \"HERITAGE19C\",\n",
    "        \"username\": \"TQ_GIS\",\n",
    "        \"password\": \"TQ_GIS\"\n",
    "    },\n",
    "    \"DATABASE_B\": { \n",
    "        \"host\": \"10.176.18.110\",\n",
    "        \"port\": 1521,\n",
    "        \"service_name\": \"NEW_GEMINIA\",\n",
    "        \"username\": \"TQ_GIS\",\n",
    "        \"password\": \"TQ_GIS\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Output Directories\n",
    "BASE_DIRECTORY = 'packages'\n",
    "DIFFS_DIRECTORY = 'diffs'\n",
    "REPORTS_DIRECTORY = 'reports'\n",
    "OUTPUT_DIRECTORY = 'output'\n",
    "CONSOLIDATED_DIRECTORY = 'consolidated_packages'\n",
    "\n",
    "# Logging Configuration - ERROR will only show errors, INFO shows all operations\n",
    "LOG_LEVEL = 'ERROR'  # Change to 'INFO' if you want detailed logging\n",
    "\n",
    "# ====================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# ====================================================================\n",
    "\n",
    "import oracledb as cx_Oracle\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import difflib\n",
    "import shutil\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL.upper(), logging.ERROR), \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Configure Google Gemini\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"Google Gemini API key not found. Please set the 'GOOGLE_API_KEY' environment variable.\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# ====================================================================\n",
    "# CORE FUNCTIONS\n",
    "# ====================================================================\n",
    "\n",
    "def clean_sql_content(content: str) -> str:\n",
    "    \"\"\"Clean SQL content by removing code blocks and extra whitespace\"\"\"\n",
    "    content = re.sub(r'^```sql\\s*\\n?', '', content, flags=re.IGNORECASE)\n",
    "    content = re.sub(r'\\n?\\s*```\\s*$', '', content)\n",
    "    content = re.sub(r'\\n?\\s*FINAL_MERGING_DONE\\s*$', '', content, flags=re.IGNORECASE)\n",
    "    return content.strip()\n",
    "\n",
    "def get_package_source(db_params, package_name, object_type='PACKAGE BODY'):\n",
    "    \"\"\"Retrieve package source code from database\"\"\"\n",
    "    logging.info(f\"Connecting to database {db_params['service_name']} to retrieve {object_type} '{package_name}'.\")\n",
    "    \n",
    "    try:\n",
    "        dsn_tns = cx_Oracle.makedsn(\n",
    "            db_params['host'],\n",
    "            db_params['port'],\n",
    "            service_name=db_params['service_name']\n",
    "        )\n",
    "        conn = cx_Oracle.connect(\n",
    "            user=db_params['username'],\n",
    "            password=db_params['password'],\n",
    "            dsn=dsn_tns\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT text\n",
    "        FROM all_source\n",
    "        WHERE name = '{package_name.upper()}'\n",
    "        AND type = '{object_type.upper()}'\n",
    "        ORDER BY line\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(query)\n",
    "        source_lines = [row[0] for row in cursor.fetchall()]\n",
    "        source = ''.join(source_lines)\n",
    "        \n",
    "        logging.info(f\"Retrieved {len(source)} characters of source code from {db_params['service_name']}.\")\n",
    "        \n",
    "    except cx_Oracle.DatabaseError as e:\n",
    "        logging.error(f\"Database connection failed: {e}\")\n",
    "        source = \"\"\n",
    "    finally:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return source\n",
    "\n",
    "def parse_package_components(source_code):\n",
    "    \"\"\"Parse package components (procedures, functions, cursors, types, variables)\"\"\"\n",
    "    logging.info(\"Parsing package components.\")\n",
    "    \n",
    "    components = {\n",
    "        'procedures': {},\n",
    "        'functions': {},\n",
    "        'cursors': {},\n",
    "        'types': {},\n",
    "        'variables': {},\n",
    "    }\n",
    "    \n",
    "    # Patterns\n",
    "    proc_pattern = re.compile(\n",
    "        r\"\"\"\n",
    "        PROCEDURE\\s+([\\w$]+)\\s*\n",
    "        \\(.*?\\)\\s*\n",
    "        (.*?)\n",
    "        (?=PROCEDURE|FUNCTION|\\Z)\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.DOTALL | re.VERBOSE\n",
    "    )\n",
    "    func_pattern = re.compile(\n",
    "        r\"\"\"\n",
    "        FUNCTION\\s+([\\w$]+)\\s*\n",
    "        \\(.*?\\)\\s*\n",
    "        (.*?)\n",
    "        (?=PROCEDURE|FUNCTION|\\Z)\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.DOTALL | re.VERBOSE\n",
    "    )\n",
    "    \n",
    "    # Procedures\n",
    "    for match in proc_pattern.finditer(source_code):\n",
    "        name = match.group(1)\n",
    "        components['procedures'][name] = match.group(0).strip()\n",
    "    # Functions\n",
    "    for match in func_pattern.finditer(source_code):\n",
    "        name = match.group(1)\n",
    "        components['functions'][name] = match.group(0).strip()\n",
    "    \n",
    "    # Declarations\n",
    "    decl_match = re.search(r'(IS|AS)\\s+(.*?)\\s+BEGIN', source_code, re.IGNORECASE | re.DOTALL)\n",
    "    if decl_match:\n",
    "        decl = decl_match.group(2)\n",
    "        cursor_pattern = re.compile(r'CURSOR\\s+([\\w$]+)\\s*(IS|AS)\\s+(.*?);', re.IGNORECASE | re.DOTALL)\n",
    "        type_pattern = re.compile(r'TYPE\\s+([\\w$]+)\\s+(IS|AS)\\s+(.*?);', re.IGNORECASE | re.DOTALL)\n",
    "        variable_pattern = re.compile(r'(\\w+)\\s+(CONSTANT\\s+)?[\\w%\\.]+(\\([\\d\\s,]*\\))?\\s*(NOT\\s+NULL)?\\s*(:=\\s*.*|)\\s*;', re.IGNORECASE | re.DOTALL)\n",
    "        for m in cursor_pattern.finditer(decl):\n",
    "            components['cursors'][m.group(1)] = m.group(0).strip()\n",
    "        for m in type_pattern.finditer(decl):\n",
    "            components['types'][m.group(1)] = m.group(0).strip()\n",
    "        for m in variable_pattern.finditer(decl):\n",
    "            components['variables'][m.group(1)] = m.group(0).strip()\n",
    "    return components\n",
    "\n",
    "def save_components_to_disk(components, package_name, base_directory=BASE_DIRECTORY):\n",
    "    \"\"\"Save package components to disk\"\"\"\n",
    "    package_dir = os.path.join(base_directory, package_name)\n",
    "    os.makedirs(package_dir, exist_ok=True)\n",
    "    for comp_type, comp_dict in components.items():\n",
    "        type_dir = os.path.join(package_dir, comp_type)\n",
    "        os.makedirs(type_dir, exist_ok=True)\n",
    "        for name, definition in comp_dict.items():\n",
    "            safe_name = ''.join(c if c.isalnum() or c in ' _-' else '_' for c in name)\n",
    "            with open(os.path.join(type_dir, f\"{safe_name}.sql\"), 'w', encoding='utf-8') as f:\n",
    "                f.write(definition)\n",
    "\n",
    "def save_components_as_json(components, package_name, base_directory=BASE_DIRECTORY):\n",
    "    \"\"\"Save components as JSON\"\"\"\n",
    "    package_dir = os.path.join(base_directory, package_name)\n",
    "    os.makedirs(package_dir, exist_ok=True)\n",
    "    with open(os.path.join(package_dir, f\"{package_name}_components.json\"), 'w', encoding='utf-8') as f:\n",
    "        json.dump(components, f, indent=4)\n",
    "\n",
    "def compare_components(components1, components2, package_name):\n",
    "    \"\"\"Compare components and generate diffs\"\"\"\n",
    "    differences = {}\n",
    "    diffs_output_dir = os.path.join(DIFFS_DIRECTORY, package_name)\n",
    "    os.makedirs(diffs_output_dir, exist_ok=True)\n",
    "    \n",
    "    for comp_type in components1.keys():\n",
    "        set1, set2 = set(components1[comp_type]), set(components2[comp_type])\n",
    "        added, removed, modified = set2 - set1, set1 - set2, set()\n",
    "        for common in set1 & set2:\n",
    "            content1 = components1[comp_type][common].strip().splitlines()\n",
    "            content2 = components2[comp_type][common].strip().splitlines()\n",
    "            if content1 != content2:\n",
    "                modified.add(common)\n",
    "                diff = difflib.unified_diff(content1, content2,\n",
    "                                            fromfile=f'{package_name}_DBA_{comp_type}_{common}.sql',\n",
    "                                            tofile=f'{package_name}_DBB_{comp_type}_{common}.sql',\n",
    "                                            lineterm='')\n",
    "                with open(os.path.join(diffs_output_dir, f'{comp_type}_{common}_diff.txt'), 'w', encoding='utf-8') as f:\n",
    "                    f.write('\\n'.join(diff))\n",
    "        differences[comp_type] = {'added': list(added), 'removed': list(removed), 'modified': list(modified)}\n",
    "    return differences\n",
    "\n",
    "def merge_database_package_procedures_with_history(differences_file_path, heritage_package_procedure, geminia_package_procedure, output_package_path):\n",
    "    \"\"\"Merge procedures using Gemini AI\"\"\"\n",
    "    generation_config = {\"temperature\": 0.2, \"top_p\": 0.95, \"max_output_tokens\": 8192, \"response_mime_type\": \"text/plain\"}\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        generation_config=generation_config,\n",
    "        system_instruction=\"You are a senior PL/SQL developer. Merge procedures and functions. End with FINAL_MERGING_DONE.\",\n",
    "    )\n",
    "    with open(differences_file_path) as f: diff_content = f.read()\n",
    "    with open(heritage_package_procedure) as f: heritage_content = f.read()\n",
    "    with open(geminia_package_procedure) as f: geminia_content = f.read()\n",
    "    base_prompt = f\"\"\"\n",
    "    Merge two PL/SQL procedures.\n",
    "    Diff (context only): {diff_content}\n",
    "    Database A: {heritage_content}\n",
    "    Database B: {geminia_content}\n",
    "    Write FINAL_MERGING_DONE at the end.\n",
    "    \"\"\"\n",
    "    merged_chunks, history = [], [{\"role\": \"user\", \"parts\": [base_prompt]}]\n",
    "    chat_session = model.start_chat(history=history)\n",
    "    while True:\n",
    "        response = chat_session.send_message(\"continue\")\n",
    "        chunk = response.text.strip()\n",
    "        merged_chunks.append(chunk)\n",
    "        history.append({\"role\": \"model\", \"parts\": [chunk]})\n",
    "        if \"FINAL_MERGING_DONE\" in chunk.upper():\n",
    "            merged_chunks[-1] = merged_chunks[-1].replace(\"FINAL_MERGING_DONE\", \"\").strip()\n",
    "            break\n",
    "        else:\n",
    "            history.append({\"role\": \"user\", \"parts\": [\"Continue.\"]})\n",
    "            chat_session = model.start_chat(history=history)\n",
    "    merged_content = clean_sql_content(\"\\n\\n\".join(merged_chunks))\n",
    "    os.makedirs(os.path.dirname(output_package_path) or \".\", exist_ok=True)\n",
    "    with open(output_package_path, \"w\") as f: f.write(merged_content)\n",
    "    return output_package_path\n",
    "\n",
    "def merge_all_database_procedures_and_functions(package_name, differences_file, heritage_path, geminia_path, output_dir):\n",
    "    \"\"\"Merge all procedures/functions or copy if only in DB_B\"\"\"\n",
    "    with open(differences_file) as f: differences = json.load(f)\n",
    "    package_output_dir = os.path.join(output_dir, package_name)\n",
    "    os.makedirs(package_output_dir, exist_ok=True)\n",
    "    merged_files = []\n",
    "    for comp_type, diff_data in differences.items():\n",
    "        if comp_type not in ['procedures', 'functions']:\n",
    "            continue\n",
    "        # modified → Gemini\n",
    "        for name in diff_data.get('modified', []):\n",
    "            diff_path = os.path.join(DIFFS_DIRECTORY, package_name, f\"{comp_type}_{name}_diff.txt\")\n",
    "            db_a_file = os.path.join(heritage_path, comp_type, f\"{name}.sql\")\n",
    "            db_b_file = os.path.join(geminia_path, comp_type, f\"{name}.sql\")\n",
    "            out_file = os.path.join(package_output_dir, f\"merged_{name}.sql\")\n",
    "            if all(os.path.exists(p) for p in [diff_path, db_a_file, db_b_file]):\n",
    "                merged_files.append(merge_database_package_procedures_with_history(diff_path, db_a_file, db_b_file, out_file))\n",
    "        # added → copy DB_B\n",
    "        for name in diff_data.get('added', []):\n",
    "            db_b_file = os.path.join(geminia_path, comp_type, f\"{name}.sql\")\n",
    "            out_file = os.path.join(package_output_dir, f\"merged_{name}.sql\")\n",
    "            if os.path.exists(db_b_file):\n",
    "                shutil.copyfile(db_b_file, out_file)\n",
    "                with open(out_file, \"r+\", encoding=\"utf-8\") as f:\n",
    "                    cleaned = clean_sql_content(f.read())\n",
    "                    f.seek(0); f.write(cleaned); f.truncate()\n",
    "                merged_files.append(out_file)\n",
    "    return merged_files\n",
    "\n",
    "def consolidate_merged_procedures_and_functions(package_name, merged_files_list, output_dir):\n",
    "    \"\"\"Consolidate all merged files into a single package\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    consolidated_path = os.path.join(output_dir, f\"{package_name}_MERGED.sql\")\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    consolidated = f\"\"\"-- =====================================================\n",
    "-- Package: {package_name}\n",
    "-- Generated: {timestamp}\n",
    "-- Description: Merged procedures and functions from Database A and B\n",
    "-- =====================================================\n",
    "\n",
    "CREATE OR REPLACE PACKAGE BODY {package_name} AS\n",
    "\n",
    "\"\"\"\n",
    "    for file_path in sorted(merged_files_list):\n",
    "        if not os.path.exists(file_path): continue\n",
    "        with open(file_path) as f: cleaned = clean_sql_content(f.read())\n",
    "        if cleaned.strip():\n",
    "            name = os.path.basename(file_path).replace('merged_', '').replace('.sql', '')\n",
    "            consolidated += f\"\\n  -- {'-'*50}\\n  -- {name.upper()}\\n  -- {'-'*50}\\n\\n\"\n",
    "            consolidated += '\\n'.join(['  ' + line if line.strip() else line for line in cleaned.splitlines()]) + \"\\n\\n\"\n",
    "    consolidated += \"END;\\n/\"\n",
    "    with open(consolidated_path, \"w\") as f: f.write(consolidated)\n",
    "    return consolidated_path\n",
    "\n",
    "def process_single_package(package_name):\n",
    "    \"\"\"Process a single package through the entire workflow\"\"\"\n",
    "    print(f\"\\n=== PROCESSING PACKAGE: {package_name} ===\")\n",
    "    src_a = get_package_source(DATABASE_CONFIGS['DATABASE_A'], package_name)\n",
    "    src_b = get_package_source(DATABASE_CONFIGS['DATABASE_B'], package_name)\n",
    "    if not src_a or not src_b:\n",
    "        print(f\"Failed to retrieve package {package_name}\")\n",
    "        return False\n",
    "    comps_a, comps_b = parse_package_components(src_a), parse_package_components(src_b)\n",
    "    save_components_to_disk(comps_a, package_name + \"_DATABASE_A_BODY\")\n",
    "    save_components_to_disk(comps_b, package_name + \"_DATABASE_B_BODY\")\n",
    "    save_components_as_json(comps_a, package_name + \"_DATABASE_A_BODY\")\n",
    "    save_components_as_json(comps_b, package_name + \"_DATABASE_B_BODY\")\n",
    "    differences = compare_components(comps_a, comps_b, package_name)\n",
    "    diff_file = os.path.join(DIFFS_DIRECTORY, package_name, \"differences.json\")\n",
    "    with open(diff_file, \"w\") as f: json.dump(differences, f, indent=4)\n",
    "    merged_files = merge_all_database_procedures_and_functions(\n",
    "        package_name, diff_file,\n",
    "        f\"packages/{package_name}_DATABASE_A_BODY\",\n",
    "        f\"packages/{package_name}_DATABASE_B_BODY\",\n",
    "        OUTPUT_DIRECTORY\n",
    "    )\n",
    "    if merged_files:\n",
    "        consolidated = consolidate_merged_procedures_and_functions(package_name, merged_files, CONSOLIDATED_DIRECTORY)\n",
    "        print(f\"Consolidated package created: {consolidated}\")\n",
    "    else:\n",
    "        print(f\"No differences to merge for {package_name}\")\n",
    "    return True\n",
    "\n",
    "def run_package_comparison():\n",
    "    \"\"\"Main entrypoint to process all packages\"\"\"\n",
    "    print(\"Starting Package Comparison and Merging Tool\")\n",
    "    for pkg in PACKAGES_TO_PROCESS:\n",
    "        process_single_package(pkg)\n",
    "    print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc59d535-7101-4ea5-9ffa-45c784c48b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Package Comparison and Merging Tool\n",
      "\n",
      "=== PROCESSING PACKAGE: GIN_STP_PKG ===\n"
     ]
    },
    {
     "ename": "PatternError",
     "evalue": "multiple repeat at position 61",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPatternError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ====================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# EXECUTION CELL - RUN THIS TO START THE PROCESS\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ====================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mrun_package_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 349\u001b[39m, in \u001b[36mrun_package_comparison\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Package Comparison and Merging Tool\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pkg \u001b[38;5;129;01min\u001b[39;00m PACKAGES_TO_PROCESS:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[43mprocess_single_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 324\u001b[39m, in \u001b[36mprocess_single_package\u001b[39m\u001b[34m(package_name)\u001b[39m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve package \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m comps_a, comps_b = \u001b[43mparse_package_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_a\u001b[49m\u001b[43m)\u001b[49m, parse_package_components(src_b)\n\u001b[32m    325\u001b[39m save_components_to_disk(comps_a, package_name + \u001b[33m\"\u001b[39m\u001b[33m_DATABASE_A_BODY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    326\u001b[39m save_components_to_disk(comps_b, package_name + \u001b[33m\"\u001b[39m\u001b[33m_DATABASE_B_BODY\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mparse_package_components\u001b[39m\u001b[34m(source_code)\u001b[39m\n\u001b[32m    173\u001b[39m cursor_pattern = re.compile(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCURSOR\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+([\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw$]+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*(IS|AS)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+(.*?);\u001b[39m\u001b[33m'\u001b[39m, re.IGNORECASE | re.DOTALL)\n\u001b[32m    174\u001b[39m type_pattern = re.compile(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTYPE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+([\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw$]+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+(IS|AS)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+(.*?);\u001b[39m\u001b[33m'\u001b[39m, re.IGNORECASE | re.DOTALL)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m variable_pattern = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mw+)\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms+(CONSTANT\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms+)?[\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m.]+(\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m([\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43md\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms,]*\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m))?\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms*(NOT\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms+NULL)?*\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms*(:=\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms*.*|)\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43ms*;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIGNORECASE\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOTALL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m cursor_pattern.finditer(decl):\n\u001b[32m    177\u001b[39m     components[\u001b[33m'\u001b[39m\u001b[33mcursors\u001b[39m\u001b[33m'\u001b[39m][m.group(\u001b[32m1\u001b[39m)] = m.group(\u001b[32m0\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:289\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile\u001b[39m(pattern, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    288\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:350\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _compiler.isstring(pattern):\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mfirst argument must be string or compiled pattern\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m p = \u001b[43m_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags & DEBUG:\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_compiler.py:743\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(p, flags)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[32m    742\u001b[39m     pattern = p\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m     p = \u001b[43m_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     pattern = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:980\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(str, flags, state)\u001b[39m\n\u001b[32m    977\u001b[39m state.flags = flags\n\u001b[32m    978\u001b[39m state.str = \u001b[38;5;28mstr\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m p = \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m p.state.flags = fix_flags(\u001b[38;5;28mstr\u001b[39m, p.state.flags)\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source.next \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:459\u001b[39m, in \u001b[36m_parse_sub\u001b[39m\u001b[34m(source, state, verbose, nested)\u001b[39m\n\u001b[32m    457\u001b[39m start = source.tell()\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    462\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:689\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(source, state, verbose, nested, first)\u001b[39m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m source.error(\u001b[33m\"\u001b[39m\u001b[33mnothing to repeat\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    687\u001b[39m                        source.tell() - here + \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _REPEATCODES:\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m source.error(\u001b[33m\"\u001b[39m\u001b[33mmultiple repeat\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    690\u001b[39m                        source.tell() - here + \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m SUBPATTERN:\n\u001b[32m    692\u001b[39m     group, add_flags, del_flags, p = item[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m]\n",
      "\u001b[31mPatternError\u001b[39m: multiple repeat at position 61"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# EXECUTION CELL - RUN THIS TO START THE PROCESS\n",
    "# ====================================================================\n",
    "\n",
    "run_package_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ef1ad-b122-4ba6-8c5a-6c13a4070b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
